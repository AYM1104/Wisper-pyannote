"""
pyannote.audioã‚’ä½¿ç”¨ã—ãŸè©±è€…åˆ†é›¢
CPUã§å®‰å®šå‹•ä½œã™ã‚‹ã‚ˆã†ã«è¨­å®š
"""

import os
import torch
from typing import List, Tuple
from pyannote.audio import Pipeline


def load_diarization_pipeline() -> Pipeline:
    """
    è©±è€…åˆ†é›¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰
    
    Returns:
        è©±è€…åˆ†é›¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    # Hugging Faceãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
    hf_token = os.getenv("HUGGINGFACE_TOKEN")
    
    if not hf_token:
        raise ValueError(
            "Hugging Faceãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
            "è©±è€…åˆ†é›¢ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®æ‰‹é †ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ãƒ»è¨­å®šã—ã¦ãã ã•ã„ï¼š\n"
            "1. https://huggingface.co/settings/tokens ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—\n"
            "2. Colabã§å®Ÿè¡Œ: os.environ['HUGGINGFACE_TOKEN'] = 'hf_your_token'\n"
            "3. ã¾ãŸã¯ã€è©±è€…åˆ†é›¢ãªã—ã§å®Ÿè¡Œ: --do_diar ãƒ•ãƒ©ã‚°ã‚’å¤–ã™"
        )
    
    print("è©±è€…åˆ†é›¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    # pyannote.audio 3.xã®è©±è€…åˆ†é›¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰
    pipeline = Pipeline.from_pretrained(
        "pyannote/speaker-diarization-3.1",
        use_auth_token=hf_token
    )
    
    # GPUãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯GPUã‚’ä½¿ç”¨ã€ãã†ã§ãªã‘ã‚Œã°CPUã‚’ä½¿ç”¨
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    pipeline = pipeline.to(device)
    print(f"è©±è€…åˆ†é›¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’{device}ã«é…ç½®ã—ã¾ã—ãŸ")
    
    print("è©±è€…åˆ†é›¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    return pipeline


def diarize(wav_path: str) -> List[Tuple[float, float, str]]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œ
    
    Args:
        wav_path: WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        è©±è€…åˆ†é›¢çµæœã®ãƒªã‚¹ãƒˆ [(start, end, speaker), ...]
    """
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰
    pipeline = load_diarization_pipeline()
    
    print("è©±è€…åˆ†é›¢ã‚’é–‹å§‹ã—ã¾ã™...")
    print("âš ï¸  è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ­£å¸¸ãªå‹•ä½œã§ã™ã€‚å‡¦ç†ã¯ç¶™ç¶šã•ã‚Œã¾ã™ã€‚")
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’å–å¾—
    try:
        import torchaudio
        info = torchaudio.info(wav_path)
        duration = info.num_frames / info.sample_rate
        print(f"ğŸ“Š éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:")
        print(f"   - ãƒ•ã‚¡ã‚¤ãƒ«: {wav_path}")
        print(f"   - é•·ã•: {duration:.1f}ç§’ ({duration/60:.1f}åˆ†)")
        print(f"   - ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {info.sample_rate}Hz")
        print(f"   - ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {info.num_channels}")
    except Exception as e:
        print(f"âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®å–å¾—ã«å¤±æ•—: {e}")
    
    # è©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œï¼ˆé€²æ—è¡¨ç¤ºä»˜ãï¼‰
    try:
        from tqdm import tqdm
        import time
        
        print("\nğŸ”„ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­...")
        print("   (ã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„)")
        
        start_time = time.time()
        
        # é€²æ—ãƒãƒ¼ä»˜ãã§è©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œ
        with tqdm(total=100, desc="è©±è€…åˆ†é›¢å‡¦ç†", unit="%") as pbar:
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆé€²æ—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
            pbar.set_description("éŸ³å£°ã‚’è§£æä¸­...")
            pbar.update(20)
            
            diarization = pipeline(wav_path)
            
            pbar.set_description("è©±è€…ã‚’è­˜åˆ¥ä¸­...")
            pbar.update(30)
            
            # çµæœã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
            results = []
            segments = list(diarization.itertracks(yield_label=True))
            
            pbar.set_description("çµæœã‚’å‡¦ç†ä¸­...")
            pbar.update(20)
            
            for i, (turn, _, speaker) in enumerate(segments):
                results.append((turn.start, turn.end, speaker))
                # é€²æ—ã‚’æ›´æ–°
                if i % max(1, len(segments) // 10) == 0:
                    pbar.update(30 / max(1, len(segments) // 10))
            
            pbar.set_description("å®Œäº†")
            pbar.update(100 - pbar.n)
        
        elapsed_time = time.time() - start_time
        print(f"\nâœ… è©±è€…åˆ†é›¢å®Œäº†!")
        print(f"   - å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’")
        print(f"   - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(results)}")
        print(f"   - è©±è€…æ•°: {len(set(speaker for _, _, speaker in results))}")
        
    except ImportError:
        # tqdmãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯é€šå¸¸å‡¦ç†
        print("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­...")
        diarization = pipeline(wav_path)
        results = []
        for turn, _, speaker in diarization.itertracks(yield_label=True):
            results.append((turn.start, turn.end, speaker))
        print(f"âœ… è©±è€…åˆ†é›¢å®Œäº†: {len(results)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
    
    return results


def diarization_to_tsv(diarization_results: List[Tuple[float, float, str]]) -> str:
    """
    è©±è€…åˆ†é›¢çµæœã‚’TSVå½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›
    
    Args:
        diarization_results: è©±è€…åˆ†é›¢çµæœã®ãƒªã‚¹ãƒˆ
        
    Returns:
        TSVå½¢å¼ã®æ–‡å­—åˆ—
    """
    tsv_lines = ["start\tend\tspeaker"]
    
    for start, end, speaker in diarization_results:
        tsv_lines.append(f"{start:.3f}\t{end:.3f}\t{speaker}")
    
    return "\n".join(tsv_lines)
