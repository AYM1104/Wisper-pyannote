"""
Colabç”¨è¶…ç°¡å˜ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ–‡å­—èµ·ã“ã—ã®ã¿ï¼‰
ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’Colabã®ã‚»ãƒ«ã«ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„
"""

# 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
import os
os.environ['COLAB_MODE'] = 'false'

print("ğŸš€ Wisper-pyannote ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹...")
!git clone https://github.com/AYM1104/Wisper-pyannote.git
%cd Wisper-pyannote
!pip install -r requirements.txt
!pip install --upgrade torch torchaudio torchvision
print("âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
print("\nğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„...")
from google.colab import files
uploaded = files.upload()
audio_file = list(uploaded.keys())[0]
print(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {audio_file}")

# 3. æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
print(f"\nğŸ¤ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™...")
print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {audio_file}")
print(f"ãƒ¢ãƒ‡ãƒ«: large-v3")
print(f"å‡ºåŠ›: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãªã—ï¼‰")

!python main.py --audio "/content/{audio_file}" --model large-v3

# 4. ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆé€²æ—ãƒãƒ¼ä»˜ãï¼‰
from tqdm import tqdm
print(f"\nğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­...")
base_name = audio_file.split('.')[0]
srt_path = f"/content/Wisper-pyannote/{base_name}.srt"

with open(srt_path, 'r', encoding='utf-8') as f:
    srt_content = f.read()

lines = srt_content.strip().split('\n')
text_lines = []

print("ãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’æŠ½å‡ºä¸­...")
for i, line in enumerate(tqdm(lines, desc="ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º")):
    line = line.strip()
    if line.isdigit() or '-->' in line or not line:
        continue
    text_lines.append(line)

text_content = '\n'.join(text_lines)
text_file = f"/content/Wisper-pyannote/{base_name}.txt"
with open(text_file, 'w', encoding='utf-8') as f:
    f.write(text_content)

print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†: {len(text_lines)}è¡Œ")

# 5. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
print(f"\nğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
files.download(text_file)
print("âœ… ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")